{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkZOkTkgXTnye66JRUU70y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshyadav1508/GAN/blob/main/DCGAN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cmdR0IxL5aKf"
      },
      "outputs": [],
      "source": [
        "# example of training a gan on mnist\n",
        "from numpy import expand_dims,zeros,ones,vstack\n",
        "from numpy.random import randn,randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Reshape,Flatten,Conv2D,Conv2DTranspose,LeakyReLU,Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_shape=(28,28,1)\n",
        "opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "n_nodes = 128 * 7 * 7\n",
        "lr=LeakyReLU(alpha=0.2)\n",
        "latent_dim = 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtGCM31N6vBQ",
        "outputId": "6caa4e2c-265c-4791-d298-46152b70da14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_discriminator():\n",
        "\n",
        "\tmodel = Sequential([\n",
        "      \n",
        "      Conv2D(64, (3,3), strides=(2, 2), padding='same',activation=lr, input_shape=in_shape),\n",
        "      Dropout(0.4),\n",
        "      Conv2D(64, (3,3), strides=(2, 2), padding='same',activation=lr),\n",
        "      Dropout(0.4),\n",
        "      Flatten(),\n",
        "      Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\t\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "so_k9Iu651g6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_generator(latent_dim):\n",
        "\n",
        "\tmodel = Sequential([\n",
        "      \n",
        "      Dense(n_nodes,activation=lr,input_dim=latent_dim),\n",
        "      Reshape((7, 7, 128)),\n",
        "      Conv2DTranspose(128, (4,4), strides=(2,2), activation=lr, padding='same'),\n",
        "      Conv2DTranspose(128, (4,4), strides=(2,2), activation=lr, padding='same'),\n",
        "      Conv2DTranspose(1, (7,7), strides=(2,2), activation='sigmoid', padding='same'),\n",
        "  ])\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "02PLzHJj60zd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_gan(g_model, d_model):\n",
        "\n",
        "\td_model.trainable = False\n",
        "\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(g_model)\n",
        "\tmodel.add(d_model)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        " \n",
        "\treturn model"
      ],
      "metadata": {
        "id": "4WA3B-_px5y6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_real_samples():\n",
        "\n",
        "\t(trainX, _), (_, _) = load_data()\n",
        "\tX = expand_dims(trainX, axis=-1)\n",
        "\tX = X.astype('float32')\n",
        "\tX = X / 255.0\n",
        "\treturn X"
      ],
      "metadata": {
        "id": "8XWmJiPbx5uQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\tX = dataset[ix]\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "metadata": {
        "id": "3Z61MuQYx5rG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "metadata": {
        "id": "0mBUuBLk790t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\tX = g_model.predict(x_input)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPc982r68GDo",
        "outputId": "db3a2a44-29d1-472a-a0c0-cafec78372ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python is awesome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plot(examples, epoch, n=10):\n",
        "\n",
        "\tfor i in range(n * n):\n",
        "\t\tpyplot.subplot(n, n, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tpyplot.savefig(filename)\n",
        "\tpyplot.close()\n",
        " "
      ],
      "metadata": {
        "id": "eWXq5W_ryZgO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        " \n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        " \n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\tfilename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "\tg_model.save(filename)"
      ],
      "metadata": {
        "id": "gh2-Ck1P2FxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=1, n_batch=256):\n",
        "\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        " \n",
        "\tfor i in range(n_epochs):\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "    \n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\n",
        "\t\t\tX, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "\t\t\td_loss, _ = d_model.train_on_batch(X, y)\n",
        "\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "\t\t\tprint('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "\t\tif (i+1) % 10 == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl4qefNe649R",
        "outputId": "48ff42ff-a019-4b37-8a45-e9dc379215cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.34568%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "\n",
        "d_model = define_discriminator()\n",
        "g_model = define_generator(latent_dim)\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "\n",
        "dataset = load_real_samples()\n",
        "\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "XbiwzsfX7DwD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}