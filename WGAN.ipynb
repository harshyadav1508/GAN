{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ATEgjrZkX-4yZa-aOZgNdRExjLBJ5hj4",
      "authorship_tag": "ABX9TyOQvOQoMtgrbAWlddek9rcD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshyadav1508/GAN/blob/main/WGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuiXIDb-Bhuf",
        "outputId": "3a70d4ee-c0fe-43c2-d356-a00244beaef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/GAN/WGAN\n",
            "/content/drive/MyDrive/Colab Notebooks/GAN/WGAN\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks/GAN/WGAN\"\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keras import backend\n",
        "from keras.constraints import Constraint\n",
        "from keras.datasets.mnist import load_data\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization\n",
        "from keras.initializers import RandomNormal\n",
        "import numpy as np\n",
        "from numpy import ones, mean, expand_dims, reshape\n",
        "from numpy.random import randn, randint\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "GkRRNTtFCjc3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clip model weights to a given hypercube"
      ],
      "metadata": {
        "id": "sLGOfvOMFujH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClipConstraint(Constraint):\n",
        "\n",
        "  def __init__(self, clip_value):\n",
        "    self.clip_value=clip_value\n",
        "\n",
        "  def __call__(self,weights):\n",
        "    return backend.clip(weights,-self.clip_value,self.clip_value)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {'clip_value':self.clip_value}"
      ],
      "metadata": {
        "id": "nLqiLAfpD3mW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate wasserstein loss"
      ],
      "metadata": {
        "id": "bhj59QDcJljN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wasserstein_loss(y_true, y_pred):\n",
        "  return backend.mean(y_true*y_pred)"
      ],
      "metadata": {
        "id": "d9tOfiVcGnvv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constant"
      ],
      "metadata": {
        "id": "f9anigrHOruF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init = RandomNormal(stddev=0.02)\n",
        "const= ClipConstraint(0.01)\n",
        "opt = RMSprop(lr=0.00005)\n",
        "latent_dim=50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3NJ5b8UOrOG",
        "outputId": "8433d9f8-e457-4f9a-eef0-9f13d4e128b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the standalone critic model"
      ],
      "metadata": {
        "id": "n1xO9N9uJ3bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_critic(in_shape=(28,28,1)):\n",
        "\n",
        "  model=Sequential([\n",
        "      Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape, activation=LeakyReLU(alpha=0.2)),\n",
        "      BatchNormalization(momentum=0.8),\n",
        "      Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, activation=LeakyReLU(alpha=0.2)),\n",
        "      BatchNormalization(momentum=0.8),\n",
        "      Flatten(),\n",
        "      Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "4EX_AUzEJpnu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the standalone generator model"
      ],
      "metadata": {
        "id": "L-koY9dozAgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import tanh\n",
        "def define_generator(latent_dim):\n",
        "\n",
        "  n_nodes=7*7*128\n",
        "  model=Sequential(\n",
        "      [\n",
        "          Dense(n_nodes, kernel_initializer=init,input_dim=latent_dim,activation=LeakyReLU(alpha=0.2)),\n",
        "          Reshape((7,7,128)),\n",
        "          Conv2DTranspose(128,(4,4),padding='same', strides=(2,2), kernel_initializer=init, activation=LeakyReLU(alpha=0.2)),\n",
        "          BatchNormalization(momentum=0.8),\n",
        "          Conv2DTranspose(128,(4,4),padding='same', strides=(2,2), kernel_initializer=init, activation=LeakyReLU(alpha=0.2)),\n",
        "          BatchNormalization(momentum=0.8),\n",
        "          Conv2D(1,(7,7),padding='same', kernel_initializer=init, activation='tanh')\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "-VVyjQf8zAOi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critic = define_generator(100)"
      ],
      "metadata": {
        "id": "AylLzx4GKbXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3814a1d-f5bc-490c-8c9a-e6f258d0f9c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 6272)              633472    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 14, 14, 128)      262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 14, 14, 128)      512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 128)      262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 28, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 1)         6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,165,313\n",
            "Trainable params: 1,164,801\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined generator and critic model,"
      ],
      "metadata": {
        "id": "_p5Zh-QO8_4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_gan(generator, critic):\n",
        "\n",
        "\n",
        "  critic.trainable=False\n",
        "\n",
        "  \n",
        "\n",
        "  model=Sequential([generator,critic])\n",
        "      \n",
        "  \n",
        "  model.compile(loss=wasserstein_loss,optimizer=opt)\n",
        "  return model"
      ],
      "metadata": {
        "id": "inFHI35hKfoB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_real_samples():\n",
        "  (trainX,trainy),(_,_)=load_data()\n",
        "  select_ix=trainy==6\n",
        "  X=trainX[select_ix]\n",
        "  X=expand_dims(X,-1)\n",
        "  X=X.astype('float')\n",
        "  X=(X-127.5)/127.5\n",
        "\n",
        "  return X\n"
      ],
      "metadata": {
        "id": "sQejPdxY-CR8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select real samples"
      ],
      "metadata": {
        "id": "Z8DXa9fzJHRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_real_samples(dataset,n_samples):\n",
        "  ix=randint(0,dataset.shape[0],n_samples)\n",
        "  X=dataset[ix]\n",
        "  y=-np.ones((n_samples,1))\n",
        "\n",
        "  return X,y\n"
      ],
      "metadata": {
        "id": "9w0jO6rU_yQS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate points in latent space as input for the generator"
      ],
      "metadata": {
        "id": "VUrvbFViLn5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_latent_points(latent_dim,n_samples):\n",
        "  x_input=randn(latent_dim*n_samples)\n",
        "  x_input=x_input.reshape(n_samples,latent_dim)\n",
        "  return x_input"
      ],
      "metadata": {
        "id": "G0lYdRovKgTb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# use the generator to generate n fake examples, with class labels"
      ],
      "metadata": {
        "id": "J5kBe_s2M4aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "  x_input=generate_latent_points(latent_dim,n_samples)\n",
        "  X=generator.predict(x_input)\n",
        "  y=np.ones((n_samples,1))\n",
        "\n",
        "  return X,y\n"
      ],
      "metadata": {
        "id": "_VrO8q-xK2bH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
        "\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(10 * 10):\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\tfilename2 = 'model_%04d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))"
      ],
      "metadata": {
        "id": "64aTWT1dMkyR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(d1_hist, d2_hist, g_hist):\n",
        "\t# plot history\n",
        "\tpyplot.plot(d1_hist, label='crit_real')\n",
        "\tpyplot.plot(d2_hist, label='crit_fake')\n",
        "\tpyplot.plot(g_hist, label='gen')\n",
        "\tpyplot.legend()\n",
        "\tpyplot.savefig('plot_line_plot_loss.png')\n",
        "\tpyplot.close()"
      ],
      "metadata": {
        "id": "fvqb99qDTF7U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "  n_steps = bat_per_epo * n_epochs\n",
        "  half_batch = int(n_batch / 2)\n",
        "  c1_hist, c2_hist, g_hist = list(), list(), list()\n",
        "\n",
        "  for i in range(n_steps):\n",
        "    c1_tmp, c2_tmp = list(), list()\n",
        "    \n",
        "    for _ in range(n_critic):\n",
        "      X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "      c_loss1 = c_model.train_on_batch(X_real, y_real)\n",
        "      c1_tmp.append(c_loss1)\n",
        "\n",
        "      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "      c_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
        "      c2_tmp.append(c_loss2)\n",
        "\n",
        "    c1_hist.append(mean(c1_tmp))\n",
        "    c2_hist.append(mean(c2_tmp))\n",
        "\n",
        "    X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "    y_gan = -ones((n_batch, 1))\n",
        "\n",
        "    g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "    g_hist.append(g_loss)\n",
        "\n",
        "\t\t\n",
        "    print('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
        "\n",
        "    if (i+1) % bat_per_epo == 0:\n",
        "      summarize_performance(i, g_model, latent_dim)\n",
        "\n",
        "    plot_history(c1_hist, c2_hist, g_hist)\n",
        "\t\t\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SNGBCzekTR4D"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 50\n",
        "# create the critic\n",
        "critic = define_critic()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, critic)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "print(dataset.shape)\n",
        "# train model\n",
        "train(generator, critic, gan_model, dataset, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-g05zoGWHz_",
        "outputId": "6c694911-1c92-40a1-9817-9fc5eb48eb4b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 6272)              319872    \n",
            "                                                                 \n",
            " reshape_13 (Reshape)        (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_26 (Conv2D  (None, 14, 14, 128)      262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_52 (Bat  (None, 14, 14, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_transpose_27 (Conv2D  (None, 28, 28, 128)      262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_53 (Bat  (None, 28, 28, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 28, 28, 1)         6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 851,713\n",
            "Trainable params: 851,201\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n",
            "(5918, 28, 28, 1)\n",
            ">1, c1=-3.241, c2=-0.048 g=-0.002\n",
            ">2, c1=-10.193, c2=-0.049 g=-0.607\n",
            ">3, c1=-14.593, c2=-0.189 g=-3.880\n",
            ">4, c1=-18.459, c2=-0.365 g=-6.960\n",
            ">5, c1=-20.286, c2=-0.672 g=-8.333\n",
            ">6, c1=-22.417, c2=-1.486 g=-8.746\n",
            ">7, c1=-24.329, c2=-2.812 g=-8.708\n",
            ">8, c1=-25.640, c2=-4.473 g=-8.762\n",
            ">9, c1=-27.449, c2=-6.390 g=-9.362\n",
            ">10, c1=-28.044, c2=-8.390 g=-9.286\n",
            ">11, c1=-29.143, c2=-9.967 g=-9.426\n",
            ">12, c1=-30.001, c2=-11.198 g=-9.468\n",
            ">13, c1=-31.276, c2=-12.275 g=-9.395\n",
            ">14, c1=-31.839, c2=-13.053 g=-9.269\n",
            ">15, c1=-31.189, c2=-13.362 g=-8.989\n",
            ">16, c1=-32.557, c2=-13.403 g=-10.313\n",
            ">17, c1=-33.418, c2=-12.520 g=-8.768\n",
            ">18, c1=-32.476, c2=-10.405 g=-11.099\n",
            ">19, c1=-33.461, c2=-8.742 g=-9.491\n",
            ">20, c1=-32.663, c2=-2.800 g=-9.510\n",
            ">21, c1=-32.519, c2=0.701 g=-11.439\n",
            ">22, c1=-33.430, c2=5.333 g=-11.822\n",
            ">23, c1=-33.057, c2=10.178 g=-11.425\n",
            ">24, c1=-34.297, c2=11.533 g=-10.474\n",
            ">25, c1=-35.144, c2=13.515 g=-8.946\n",
            ">26, c1=-35.228, c2=13.225 g=-7.134\n",
            ">27, c1=-35.807, c2=12.413 g=-5.337\n",
            ">28, c1=-34.843, c2=12.051 g=-4.509\n",
            ">29, c1=-36.517, c2=10.862 g=-3.045\n",
            ">30, c1=-35.748, c2=8.942 g=-2.201\n",
            ">31, c1=-36.505, c2=7.605 g=-0.778\n",
            ">32, c1=-37.772, c2=6.422 g=0.514\n",
            ">33, c1=-37.877, c2=5.639 g=1.154\n",
            ">34, c1=-38.542, c2=3.245 g=0.981\n",
            ">35, c1=-40.904, c2=2.507 g=1.955\n",
            ">36, c1=-39.921, c2=1.490 g=2.319\n",
            ">37, c1=-39.731, c2=1.236 g=2.891\n",
            ">38, c1=-39.975, c2=1.290 g=3.339\n",
            ">39, c1=-41.718, c2=1.421 g=2.630\n",
            ">40, c1=-40.774, c2=1.410 g=3.112\n",
            ">41, c1=-41.618, c2=0.093 g=3.587\n",
            ">42, c1=-41.729, c2=-0.066 g=3.577\n",
            ">43, c1=-42.799, c2=-1.249 g=3.246\n",
            ">44, c1=-42.825, c2=-2.088 g=3.800\n",
            ">45, c1=-43.255, c2=-3.147 g=4.440\n",
            ">46, c1=-45.041, c2=-3.269 g=5.354\n",
            ">47, c1=-47.025, c2=-4.067 g=5.249\n",
            ">48, c1=-47.478, c2=-5.378 g=5.392\n",
            ">49, c1=-48.622, c2=-5.811 g=6.081\n",
            ">50, c1=-49.066, c2=-6.932 g=6.967\n",
            ">51, c1=-49.512, c2=-7.862 g=7.071\n",
            ">52, c1=-51.391, c2=-9.910 g=8.142\n",
            ">53, c1=-51.464, c2=-8.794 g=7.832\n",
            ">54, c1=-53.911, c2=-10.532 g=8.889\n",
            ">55, c1=-54.539, c2=-10.191 g=9.003\n",
            ">56, c1=-55.877, c2=-7.175 g=8.561\n",
            ">57, c1=-55.646, c2=-4.894 g=3.161\n",
            ">58, c1=-56.630, c2=0.097 g=0.459\n",
            ">59, c1=-57.490, c2=1.721 g=-0.982\n",
            ">60, c1=-60.435, c2=0.985 g=-1.867\n",
            ">61, c1=-61.302, c2=-1.550 g=-0.933\n",
            ">62, c1=-60.708, c2=-5.750 g=2.683\n",
            ">63, c1=-62.506, c2=-7.830 g=4.305\n",
            ">64, c1=-63.918, c2=-8.203 g=5.428\n",
            ">65, c1=-63.232, c2=-7.772 g=4.672\n",
            ">66, c1=-65.667, c2=-5.778 g=3.451\n",
            ">67, c1=-65.363, c2=-6.264 g=3.610\n",
            ">68, c1=-66.637, c2=-7.247 g=5.180\n",
            ">69, c1=-67.301, c2=-8.444 g=4.666\n",
            ">70, c1=-68.182, c2=-8.223 g=4.440\n",
            ">71, c1=-68.932, c2=-7.281 g=3.850\n",
            ">72, c1=-70.208, c2=-5.870 g=2.266\n",
            ">73, c1=-70.619, c2=-2.264 g=-1.832\n",
            ">74, c1=-72.958, c2=-2.871 g=-1.035\n",
            ">75, c1=-71.678, c2=-3.372 g=-2.114\n",
            ">76, c1=-74.863, c2=-3.521 g=-2.217\n",
            ">77, c1=-75.450, c2=-2.351 g=-1.834\n",
            ">78, c1=-77.253, c2=-1.785 g=-3.773\n",
            ">79, c1=-76.733, c2=1.626 g=-4.788\n",
            ">80, c1=-76.639, c2=4.657 g=-7.075\n",
            ">81, c1=-79.383, c2=2.431 g=-4.856\n",
            ">82, c1=-79.479, c2=1.323 g=-4.617\n",
            ">83, c1=-81.511, c2=-1.183 g=-3.928\n",
            ">84, c1=-81.297, c2=-1.332 g=-3.289\n",
            ">85, c1=-82.513, c2=-1.793 g=-3.167\n",
            ">86, c1=-84.139, c2=-1.469 g=-3.944\n",
            ">87, c1=-85.521, c2=0.039 g=-4.461\n",
            ">88, c1=-85.114, c2=-0.086 g=-5.518\n",
            ">89, c1=-86.938, c2=0.654 g=-6.284\n",
            ">90, c1=-87.038, c2=-0.702 g=-5.394\n",
            ">91, c1=-88.275, c2=-2.124 g=-4.505\n",
            ">92, c1=-89.999, c2=-3.101 g=-3.902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0092.png and model_0092.h5\n",
            ">93, c1=-89.293, c2=-1.910 g=-6.247\n",
            ">94, c1=-89.964, c2=0.371 g=-6.228\n",
            ">95, c1=-92.422, c2=0.616 g=-6.380\n",
            ">96, c1=-92.361, c2=-0.239 g=-6.730\n",
            ">97, c1=-93.723, c2=-1.814 g=-5.796\n",
            ">98, c1=-94.880, c2=-3.836 g=-5.373\n",
            ">99, c1=-96.011, c2=-2.904 g=-4.945\n",
            ">100, c1=-96.235, c2=-4.561 g=-5.346\n",
            ">101, c1=-97.635, c2=-5.625 g=-5.911\n",
            ">102, c1=-98.026, c2=-4.821 g=-6.007\n",
            ">103, c1=-98.713, c2=-5.662 g=-5.270\n",
            ">104, c1=-100.124, c2=-7.101 g=-4.902\n",
            ">105, c1=-99.890, c2=-7.368 g=-4.281\n",
            ">106, c1=-101.845, c2=-8.019 g=-4.331\n",
            ">107, c1=-102.778, c2=-8.394 g=-3.950\n",
            ">108, c1=-102.462, c2=-7.443 g=-4.656\n",
            ">109, c1=-102.435, c2=-9.244 g=-5.922\n",
            ">110, c1=-103.431, c2=-8.958 g=-7.164\n",
            ">111, c1=-105.056, c2=-8.623 g=-7.115\n",
            ">112, c1=-105.285, c2=-9.734 g=-6.120\n",
            ">113, c1=-107.147, c2=-7.569 g=-9.542\n",
            ">114, c1=-106.256, c2=-8.625 g=-8.702\n",
            ">115, c1=-108.435, c2=-6.874 g=-11.126\n",
            ">116, c1=-109.376, c2=-8.076 g=-10.025\n",
            ">117, c1=-109.212, c2=-7.261 g=-11.299\n",
            ">118, c1=-110.904, c2=-5.509 g=-11.755\n",
            ">119, c1=-111.643, c2=-9.108 g=-12.185\n",
            ">120, c1=-112.839, c2=-7.374 g=-13.649\n",
            ">121, c1=-113.318, c2=-7.563 g=-14.912\n",
            ">122, c1=-114.844, c2=-9.758 g=-12.836\n",
            ">123, c1=-114.042, c2=-5.133 g=-17.010\n",
            ">124, c1=-114.671, c2=-7.901 g=-15.255\n",
            ">125, c1=-116.227, c2=-5.685 g=-18.363\n",
            ">126, c1=-115.919, c2=-4.765 g=-19.326\n",
            ">127, c1=-116.430, c2=-2.930 g=-20.621\n",
            ">128, c1=-118.037, c2=-4.298 g=-16.354\n",
            ">129, c1=-119.360, c2=-6.597 g=-21.102\n",
            ">130, c1=-120.358, c2=-2.780 g=-21.508\n",
            ">131, c1=-120.187, c2=-5.731 g=-21.032\n",
            ">132, c1=-122.320, c2=-4.773 g=-21.325\n",
            ">133, c1=-121.004, c2=-4.809 g=-23.075\n",
            ">134, c1=-121.714, c2=-11.828 g=-17.378\n",
            ">135, c1=-121.082, c2=-9.677 g=-17.867\n",
            ">136, c1=-122.513, c2=-3.887 g=-21.981\n",
            ">137, c1=-125.125, c2=-8.891 g=-22.628\n",
            ">138, c1=-125.169, c2=-5.304 g=-23.858\n",
            ">139, c1=-127.580, c2=-12.098 g=-19.153\n",
            ">140, c1=-126.625, c2=-13.088 g=-20.687\n",
            ">141, c1=-127.991, c2=-14.946 g=-20.682\n",
            ">142, c1=-128.305, c2=-14.737 g=-18.961\n",
            ">143, c1=-127.417, c2=-15.347 g=-18.174\n",
            ">144, c1=-130.323, c2=-10.034 g=-23.938\n",
            ">145, c1=-129.666, c2=-10.568 g=-23.952\n",
            ">146, c1=-130.728, c2=-16.056 g=-21.362\n",
            ">147, c1=-131.669, c2=-18.876 g=-21.202\n",
            ">148, c1=-131.567, c2=-11.723 g=-25.269\n",
            ">149, c1=-131.654, c2=-18.588 g=-21.068\n",
            ">150, c1=-133.067, c2=-8.006 g=-24.055\n",
            ">151, c1=-133.168, c2=-11.019 g=-26.024\n",
            ">152, c1=-132.755, c2=-21.718 g=-18.449\n",
            ">153, c1=-134.651, c2=-9.866 g=-23.084\n",
            ">154, c1=-134.498, c2=-11.128 g=-24.744\n",
            ">155, c1=-137.427, c2=-18.549 g=-20.918\n",
            ">156, c1=-137.297, c2=-21.997 g=-19.128\n",
            ">157, c1=-137.620, c2=-24.322 g=-22.871\n",
            ">158, c1=-138.437, c2=-19.252 g=-23.884\n",
            ">159, c1=-138.902, c2=-20.058 g=-23.341\n",
            ">160, c1=-140.174, c2=-21.307 g=-21.377\n",
            ">161, c1=-141.450, c2=-22.886 g=-24.897\n",
            ">162, c1=-141.206, c2=-24.475 g=-20.814\n",
            ">163, c1=-142.422, c2=-21.344 g=-22.664\n",
            ">164, c1=-143.451, c2=-16.413 g=-26.732\n",
            ">165, c1=-144.348, c2=-22.308 g=-25.841\n",
            ">166, c1=-145.144, c2=-28.896 g=-21.725\n",
            ">167, c1=-145.220, c2=-20.353 g=-22.025\n",
            ">168, c1=-147.890, c2=-23.833 g=-25.580\n",
            ">169, c1=-146.957, c2=-28.395 g=-22.822\n",
            ">170, c1=-147.763, c2=-30.380 g=-22.478\n",
            ">171, c1=-149.212, c2=-22.788 g=-26.048\n",
            ">172, c1=-148.296, c2=-29.294 g=-21.363\n",
            ">173, c1=-150.213, c2=-26.434 g=-25.772\n",
            ">174, c1=-150.335, c2=-24.625 g=-25.434\n",
            ">175, c1=-150.044, c2=-29.607 g=-25.807\n",
            ">176, c1=-150.375, c2=-25.120 g=-28.928\n",
            ">177, c1=-152.009, c2=-23.070 g=-28.669\n",
            ">178, c1=-153.298, c2=-36.370 g=-24.051\n",
            ">179, c1=-155.874, c2=-33.953 g=-23.916\n",
            ">180, c1=-154.012, c2=-26.128 g=-28.336\n",
            ">181, c1=-156.459, c2=-29.444 g=-24.801\n",
            ">182, c1=-157.236, c2=-24.822 g=-29.746\n",
            ">183, c1=-157.576, c2=-41.888 g=-21.208\n",
            ">184, c1=-159.851, c2=-31.985 g=-28.194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0184.png and model_0184.h5\n",
            ">185, c1=-157.167, c2=-29.037 g=-30.005\n",
            ">186, c1=-161.794, c2=-41.407 g=-25.473\n",
            ">187, c1=-161.843, c2=-28.911 g=-30.800\n",
            ">188, c1=-163.754, c2=-46.918 g=-22.263\n",
            ">189, c1=-161.946, c2=-27.463 g=-28.096\n",
            ">190, c1=-165.099, c2=-42.291 g=-28.881\n",
            ">191, c1=-165.427, c2=-32.463 g=-28.966\n",
            ">192, c1=-165.427, c2=-38.181 g=-26.243\n",
            ">193, c1=-167.955, c2=-37.926 g=-31.420\n",
            ">194, c1=-167.261, c2=-41.354 g=-26.584\n",
            ">195, c1=-172.166, c2=-45.018 g=-28.579\n",
            ">196, c1=-169.875, c2=-36.549 g=-30.294\n",
            ">197, c1=-170.337, c2=-30.640 g=-34.252\n",
            ">198, c1=-170.451, c2=-33.990 g=-29.443\n",
            ">199, c1=-173.782, c2=-45.609 g=-29.787\n",
            ">200, c1=-174.677, c2=-41.323 g=-30.278\n",
            ">201, c1=-173.022, c2=-42.525 g=-28.996\n",
            ">202, c1=-174.755, c2=-37.167 g=-35.506\n",
            ">203, c1=-173.712, c2=-46.415 g=-29.519\n",
            ">204, c1=-177.509, c2=-42.083 g=-33.131\n",
            ">205, c1=-177.353, c2=-37.910 g=-35.254\n",
            ">206, c1=-178.167, c2=-54.744 g=-28.892\n",
            ">207, c1=-181.110, c2=-56.338 g=-22.933\n",
            ">208, c1=-184.024, c2=-55.643 g=-27.973\n",
            ">209, c1=-180.914, c2=-46.745 g=-26.834\n",
            ">210, c1=-182.820, c2=-58.051 g=-28.722\n",
            ">211, c1=-182.233, c2=-51.499 g=-26.913\n",
            ">212, c1=-185.030, c2=-55.282 g=-24.580\n",
            ">213, c1=-186.399, c2=-53.148 g=-31.840\n",
            ">214, c1=-183.674, c2=-37.292 g=-41.119\n",
            ">215, c1=-184.906, c2=-54.098 g=-27.029\n",
            ">216, c1=-189.495, c2=-48.184 g=-34.172\n",
            ">217, c1=-188.094, c2=-52.982 g=-35.079\n",
            ">218, c1=-189.100, c2=-45.766 g=-41.302\n",
            ">219, c1=-189.579, c2=-49.144 g=-36.731\n",
            ">220, c1=-189.296, c2=-54.452 g=-30.788\n",
            ">221, c1=-192.902, c2=-58.443 g=-31.959\n",
            ">222, c1=-192.717, c2=-53.801 g=-36.486\n",
            ">223, c1=-193.677, c2=-54.835 g=-38.123\n",
            ">224, c1=-193.740, c2=-49.495 g=-35.330\n",
            ">225, c1=-193.926, c2=-51.866 g=-36.924\n",
            ">226, c1=-195.275, c2=-50.503 g=-36.392\n",
            ">227, c1=-199.245, c2=-59.591 g=-32.998\n",
            ">228, c1=-195.162, c2=-50.288 g=-36.331\n",
            ">229, c1=-196.309, c2=-45.775 g=-36.063\n",
            ">230, c1=-197.024, c2=-48.661 g=-41.526\n",
            ">231, c1=-197.373, c2=-38.191 g=-42.264\n",
            ">232, c1=-199.098, c2=-55.155 g=-34.797\n",
            ">233, c1=-200.404, c2=-55.050 g=-38.507\n",
            ">234, c1=-204.143, c2=-68.638 g=-30.912\n",
            ">235, c1=-205.058, c2=-66.654 g=-25.181\n",
            ">236, c1=-204.234, c2=-64.483 g=-30.353\n",
            ">237, c1=-205.673, c2=-61.585 g=-34.865\n",
            ">238, c1=-205.703, c2=-61.742 g=-36.505\n",
            ">239, c1=-207.000, c2=-72.302 g=-26.014\n",
            ">240, c1=-207.992, c2=-64.076 g=-32.751\n",
            ">241, c1=-210.127, c2=-69.905 g=-26.431\n",
            ">242, c1=-211.774, c2=-61.490 g=-30.131\n",
            ">243, c1=-210.222, c2=-60.014 g=-34.718\n",
            ">244, c1=-211.338, c2=-69.234 g=-29.917\n",
            ">245, c1=-212.403, c2=-67.485 g=-28.570\n",
            ">246, c1=-209.669, c2=-62.444 g=-36.197\n",
            ">247, c1=-216.153, c2=-82.838 g=-30.100\n",
            ">248, c1=-218.305, c2=-82.305 g=-24.424\n",
            ">249, c1=-217.960, c2=-66.021 g=-35.657\n",
            ">250, c1=-214.783, c2=-73.005 g=-24.421\n",
            ">251, c1=-218.522, c2=-67.768 g=-32.992\n",
            ">252, c1=-220.925, c2=-81.854 g=-26.562\n",
            ">253, c1=-220.172, c2=-72.859 g=-32.283\n",
            ">254, c1=-219.708, c2=-62.623 g=-39.630\n",
            ">255, c1=-222.048, c2=-78.409 g=-29.584\n",
            ">256, c1=-226.322, c2=-100.185 g=-20.814\n",
            ">257, c1=-224.918, c2=-79.752 g=-31.570\n",
            ">258, c1=-226.577, c2=-82.887 g=-35.707\n",
            ">259, c1=-228.751, c2=-89.257 g=-25.490\n",
            ">260, c1=-229.336, c2=-78.264 g=-28.762\n",
            ">261, c1=-227.249, c2=-79.561 g=-31.092\n",
            ">262, c1=-229.754, c2=-77.984 g=-31.608\n",
            ">263, c1=-228.858, c2=-92.756 g=-22.437\n",
            ">264, c1=-230.165, c2=-88.665 g=-16.413\n",
            ">265, c1=-228.166, c2=-61.650 g=-33.051\n",
            ">266, c1=-230.836, c2=-91.735 g=-23.295\n",
            ">267, c1=-233.865, c2=-83.215 g=-27.880\n",
            ">268, c1=-233.869, c2=-85.692 g=-33.912\n",
            ">269, c1=-235.094, c2=-81.884 g=-34.410\n",
            ">270, c1=-236.436, c2=-80.329 g=-36.932\n",
            ">271, c1=-235.436, c2=-74.383 g=-35.990\n",
            ">272, c1=-241.372, c2=-84.994 g=-24.293\n",
            ">273, c1=-232.243, c2=-72.069 g=-29.522\n",
            ">274, c1=-236.458, c2=-97.358 g=-21.063\n",
            ">275, c1=-240.601, c2=-96.632 g=-18.957\n",
            ">276, c1=-239.145, c2=-97.095 g=-17.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0276.png and model_0276.h5\n",
            ">277, c1=-240.991, c2=-95.617 g=-22.471\n",
            ">278, c1=-245.119, c2=-111.137 g=-10.550\n",
            ">279, c1=-248.304, c2=-112.230 g=-16.525\n",
            ">280, c1=-245.459, c2=-87.795 g=-28.441\n",
            ">281, c1=-245.073, c2=-96.858 g=-27.534\n",
            ">282, c1=-243.428, c2=-95.571 g=-22.805\n",
            ">283, c1=-250.869, c2=-120.784 g=-14.845\n",
            ">284, c1=-251.063, c2=-105.951 g=-16.593\n",
            ">285, c1=-248.203, c2=-83.961 g=-26.646\n",
            ">286, c1=-250.822, c2=-109.635 g=-19.897\n",
            ">287, c1=-250.624, c2=-100.356 g=-19.084\n",
            ">288, c1=-252.129, c2=-92.164 g=-25.761\n",
            ">289, c1=-251.613, c2=-95.675 g=-28.156\n",
            ">290, c1=-251.559, c2=-81.707 g=-29.977\n",
            ">291, c1=-248.463, c2=-96.971 g=-22.999\n",
            ">292, c1=-256.048, c2=-116.264 g=-18.645\n",
            ">293, c1=-256.250, c2=-104.980 g=-18.078\n",
            ">294, c1=-257.279, c2=-113.113 g=-10.628\n",
            ">295, c1=-259.204, c2=-102.488 g=-21.500\n",
            ">296, c1=-259.638, c2=-123.267 g=-9.034\n",
            ">297, c1=-262.851, c2=-121.545 g=-10.769\n",
            ">298, c1=-264.972, c2=-121.007 g=-15.586\n",
            ">299, c1=-262.284, c2=-105.193 g=-21.317\n",
            ">300, c1=-259.410, c2=-96.055 g=-22.825\n",
            ">301, c1=-260.498, c2=-117.761 g=-20.611\n",
            ">302, c1=-266.382, c2=-111.268 g=-17.562\n",
            ">303, c1=-267.690, c2=-106.730 g=-20.777\n",
            ">304, c1=-259.435, c2=-87.445 g=-26.339\n",
            ">305, c1=-260.708, c2=-123.126 g=-2.813\n",
            ">306, c1=-264.283, c2=-108.813 g=-18.547\n",
            ">307, c1=-266.293, c2=-104.861 g=-20.100\n",
            ">308, c1=-266.091, c2=-126.369 g=-11.363\n",
            ">309, c1=-269.768, c2=-102.343 g=-26.929\n",
            ">310, c1=-271.444, c2=-132.562 g=-10.126\n",
            ">311, c1=-270.724, c2=-109.816 g=-18.962\n",
            ">312, c1=-269.359, c2=-114.693 g=-19.605\n",
            ">313, c1=-268.308, c2=-115.958 g=-9.258\n",
            ">314, c1=-274.027, c2=-100.853 g=-17.636\n",
            ">315, c1=-269.824, c2=-115.726 g=-3.848\n",
            ">316, c1=-274.441, c2=-117.990 g=-11.325\n",
            ">317, c1=-273.994, c2=-136.429 g=-0.891\n",
            ">318, c1=-281.369, c2=-141.695 g=-8.932\n",
            ">319, c1=-277.282, c2=-124.892 g=-6.174\n",
            ">320, c1=-280.831, c2=-129.190 g=-9.967\n",
            ">321, c1=-278.156, c2=-118.700 g=-18.794\n",
            ">322, c1=-279.769, c2=-110.323 g=-27.382\n",
            ">323, c1=-284.778, c2=-138.911 g=-4.520\n",
            ">324, c1=-282.658, c2=-130.963 g=-5.581\n",
            ">325, c1=-284.206, c2=-115.203 g=-20.494\n",
            ">326, c1=-280.660, c2=-118.762 g=-9.746\n",
            ">327, c1=-284.404, c2=-120.103 g=0.502\n",
            ">328, c1=-286.901, c2=-131.801 g=-2.834\n",
            ">329, c1=-286.366, c2=-134.125 g=0.441\n",
            ">330, c1=-285.449, c2=-150.511 g=4.064\n",
            ">331, c1=-292.806, c2=-122.080 g=-18.376\n",
            ">332, c1=-288.767, c2=-147.871 g=-3.954\n",
            ">333, c1=-291.212, c2=-133.296 g=-8.804\n",
            ">334, c1=-294.523, c2=-127.857 g=-13.103\n",
            ">335, c1=-292.552, c2=-142.360 g=-5.539\n",
            ">336, c1=-288.980, c2=-135.907 g=-2.549\n",
            ">337, c1=-285.957, c2=-126.196 g=-0.889\n",
            ">338, c1=-295.870, c2=-150.270 g=0.417\n",
            ">339, c1=-294.959, c2=-140.072 g=-13.179\n",
            ">340, c1=-294.136, c2=-121.437 g=-14.808\n",
            ">341, c1=-297.138, c2=-141.573 g=-1.373\n",
            ">342, c1=-296.568, c2=-174.035 g=6.523\n",
            ">343, c1=-305.590, c2=-141.665 g=-8.473\n",
            ">344, c1=-306.650, c2=-185.818 g=20.692\n",
            ">345, c1=-308.519, c2=-135.222 g=-13.286\n",
            ">346, c1=-303.178, c2=-148.159 g=-12.340\n",
            ">347, c1=-303.755, c2=-128.159 g=-16.594\n",
            ">348, c1=-307.806, c2=-167.180 g=-3.344\n",
            ">349, c1=-308.044, c2=-141.114 g=-10.529\n",
            ">350, c1=-308.750, c2=-134.206 g=-12.472\n",
            ">351, c1=-303.406, c2=-147.415 g=-8.384\n",
            ">352, c1=-302.335, c2=-117.648 g=-5.777\n",
            ">353, c1=-312.360, c2=-172.908 g=3.249\n",
            ">354, c1=-308.310, c2=-132.182 g=-10.890\n",
            ">355, c1=-301.135, c2=-96.908 g=-25.636\n",
            ">356, c1=-307.726, c2=-118.922 g=-23.992\n",
            ">357, c1=-308.772, c2=-132.756 g=-11.243\n",
            ">358, c1=-303.166, c2=-118.406 g=-19.185\n",
            ">359, c1=-310.471, c2=-170.276 g=-1.618\n",
            ">360, c1=-311.889, c2=-147.500 g=3.644\n",
            ">361, c1=-311.620, c2=-149.731 g=-8.110\n",
            ">362, c1=-312.938, c2=-140.765 g=-16.462\n",
            ">363, c1=-310.296, c2=-134.751 g=-12.205\n",
            ">364, c1=-313.245, c2=-150.535 g=-5.616\n",
            ">365, c1=-318.014, c2=-154.139 g=-2.864\n",
            ">366, c1=-317.188, c2=-171.777 g=13.159\n",
            ">367, c1=-327.324, c2=-184.137 g=3.104\n",
            ">368, c1=-313.311, c2=-136.058 g=1.043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0368.png and model_0368.h5\n",
            ">369, c1=-317.726, c2=-155.520 g=0.700\n",
            ">370, c1=-327.212, c2=-161.016 g=-1.052\n",
            ">371, c1=-319.256, c2=-187.017 g=13.898\n",
            ">372, c1=-326.939, c2=-149.202 g=-12.278\n",
            ">373, c1=-319.515, c2=-143.517 g=-8.143\n",
            ">374, c1=-321.426, c2=-148.796 g=-4.909\n",
            ">375, c1=-319.265, c2=-152.742 g=-10.334\n",
            ">376, c1=-327.784, c2=-149.588 g=-8.198\n",
            ">377, c1=-324.985, c2=-139.762 g=-10.009\n",
            ">378, c1=-330.342, c2=-158.593 g=-1.858\n",
            ">379, c1=-323.952, c2=-116.182 g=-38.619\n",
            ">380, c1=-319.647, c2=-147.064 g=-5.035\n",
            ">381, c1=-323.849, c2=-147.546 g=-9.319\n",
            ">382, c1=-326.681, c2=-105.899 g=-19.373\n",
            ">383, c1=-317.995, c2=-136.032 g=-1.442\n",
            ">384, c1=-321.231, c2=-145.321 g=-3.749\n",
            ">385, c1=-324.522, c2=-143.735 g=-10.071\n",
            ">386, c1=-328.282, c2=-171.477 g=8.283\n",
            ">387, c1=-329.107, c2=-163.453 g=7.303\n",
            ">388, c1=-341.701, c2=-195.486 g=12.047\n",
            ">389, c1=-343.061, c2=-198.109 g=18.255\n",
            ">390, c1=-337.461, c2=-166.767 g=12.427\n",
            ">391, c1=-353.120, c2=-180.692 g=-5.002\n",
            ">392, c1=-336.964, c2=-142.178 g=-27.477\n",
            ">393, c1=-339.059, c2=-176.655 g=4.679\n",
            ">394, c1=-335.057, c2=-140.121 g=13.204\n",
            ">395, c1=-342.692, c2=-167.940 g=2.944\n",
            ">396, c1=-335.091, c2=-143.140 g=-12.961\n",
            ">397, c1=-341.572, c2=-136.011 g=-8.482\n",
            ">398, c1=-335.512, c2=-161.315 g=-13.279\n",
            ">399, c1=-329.442, c2=-150.497 g=-0.868\n",
            ">400, c1=-337.638, c2=-142.694 g=8.675\n",
            ">401, c1=-341.120, c2=-174.852 g=20.797\n",
            ">402, c1=-341.887, c2=-198.646 g=22.024\n",
            ">403, c1=-352.222, c2=-202.131 g=18.558\n",
            ">404, c1=-351.742, c2=-169.235 g=4.616\n",
            ">405, c1=-344.100, c2=-144.417 g=-27.046\n",
            ">406, c1=-339.639, c2=-159.143 g=6.620\n",
            ">407, c1=-343.462, c2=-179.832 g=16.415\n",
            ">408, c1=-342.801, c2=-160.067 g=4.499\n",
            ">409, c1=-350.237, c2=-161.734 g=10.023\n",
            ">410, c1=-353.437, c2=-166.667 g=16.601\n",
            ">411, c1=-347.178, c2=-148.246 g=5.953\n",
            ">412, c1=-357.603, c2=-190.647 g=1.396\n",
            ">413, c1=-351.120, c2=-179.047 g=20.881\n",
            ">414, c1=-356.768, c2=-193.342 g=19.954\n",
            ">415, c1=-351.872, c2=-174.205 g=-3.370\n",
            ">416, c1=-347.185, c2=-143.134 g=-10.829\n",
            ">417, c1=-340.817, c2=-149.357 g=-2.739\n",
            ">418, c1=-361.197, c2=-182.434 g=10.050\n",
            ">419, c1=-355.935, c2=-148.818 g=-1.733\n",
            ">420, c1=-343.365, c2=-156.420 g=0.099\n",
            ">421, c1=-351.359, c2=-166.134 g=5.694\n",
            ">422, c1=-363.363, c2=-199.723 g=22.756\n",
            ">423, c1=-367.311, c2=-206.695 g=4.026\n",
            ">424, c1=-359.461, c2=-165.330 g=-13.183\n",
            ">425, c1=-351.474, c2=-116.421 g=-25.052\n",
            ">426, c1=-359.925, c2=-171.283 g=-4.100\n",
            ">427, c1=-362.569, c2=-187.742 g=15.049\n",
            ">428, c1=-363.208, c2=-157.661 g=9.309\n",
            ">429, c1=-367.704, c2=-195.840 g=4.997\n",
            ">430, c1=-366.749, c2=-181.800 g=-1.545\n",
            ">431, c1=-359.845, c2=-173.298 g=8.152\n",
            ">432, c1=-380.658, c2=-185.523 g=-14.824\n",
            ">433, c1=-352.772, c2=-107.715 g=-32.558\n",
            ">434, c1=-369.288, c2=-187.813 g=10.521\n",
            ">435, c1=-364.034, c2=-179.055 g=4.958\n",
            ">436, c1=-365.714, c2=-147.887 g=-11.965\n",
            ">437, c1=-360.267, c2=-197.923 g=14.420\n",
            ">438, c1=-364.317, c2=-169.426 g=-0.124\n",
            ">439, c1=-363.439, c2=-141.777 g=5.990\n",
            ">440, c1=-366.696, c2=-158.589 g=8.703\n",
            ">441, c1=-371.289, c2=-213.702 g=24.731\n",
            ">442, c1=-362.287, c2=-156.002 g=1.215\n",
            ">443, c1=-365.627, c2=-190.421 g=8.637\n",
            ">444, c1=-383.361, c2=-231.208 g=13.873\n",
            ">445, c1=-375.660, c2=-173.828 g=18.201\n",
            ">446, c1=-394.209, c2=-238.947 g=28.858\n",
            ">447, c1=-391.812, c2=-216.395 g=24.632\n",
            ">448, c1=-388.994, c2=-199.033 g=9.812\n",
            ">449, c1=-379.948, c2=-208.802 g=13.699\n",
            ">450, c1=-387.035, c2=-168.248 g=-3.298\n",
            ">451, c1=-381.500, c2=-203.198 g=10.227\n",
            ">452, c1=-393.679, c2=-200.735 g=8.178\n",
            ">453, c1=-377.278, c2=-130.735 g=-22.507\n",
            ">454, c1=-376.389, c2=-167.770 g=-7.971\n",
            ">455, c1=-373.799, c2=-176.306 g=-11.214\n",
            ">456, c1=-385.563, c2=-232.796 g=46.048\n",
            ">457, c1=-399.662, c2=-203.870 g=14.667\n",
            ">458, c1=-384.407, c2=-234.725 g=13.814\n",
            ">459, c1=-391.889, c2=-188.379 g=-2.548\n",
            ">460, c1=-395.661, c2=-158.577 g=-6.647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0460.png and model_0460.h5\n",
            ">461, c1=-381.320, c2=-181.530 g=4.583\n",
            ">462, c1=-392.959, c2=-198.191 g=7.096\n",
            ">463, c1=-386.619, c2=-159.048 g=6.447\n",
            ">464, c1=-376.901, c2=-168.008 g=-0.212\n",
            ">465, c1=-385.385, c2=-190.701 g=18.782\n",
            ">466, c1=-390.395, c2=-208.778 g=12.705\n",
            ">467, c1=-392.513, c2=-156.533 g=-15.058\n",
            ">468, c1=-381.212, c2=-176.828 g=11.784\n",
            ">469, c1=-391.745, c2=-185.752 g=4.517\n",
            ">470, c1=-387.593, c2=-171.166 g=6.108\n",
            ">471, c1=-382.922, c2=-176.621 g=5.579\n",
            ">472, c1=-384.007, c2=-166.295 g=-16.043\n",
            ">473, c1=-381.194, c2=-196.251 g=-3.632\n",
            ">474, c1=-391.498, c2=-172.708 g=5.246\n",
            ">475, c1=-389.737, c2=-215.064 g=9.569\n",
            ">476, c1=-397.717, c2=-144.496 g=-9.808\n",
            ">477, c1=-395.782, c2=-215.644 g=15.149\n",
            ">478, c1=-395.201, c2=-237.857 g=20.489\n",
            ">479, c1=-400.991, c2=-170.274 g=23.571\n",
            ">480, c1=-408.482, c2=-194.558 g=-5.001\n",
            ">481, c1=-393.353, c2=-185.286 g=11.673\n",
            ">482, c1=-400.777, c2=-191.198 g=8.303\n",
            ">483, c1=-391.643, c2=-175.779 g=-28.141\n",
            ">484, c1=-393.203, c2=-191.533 g=6.580\n",
            ">485, c1=-411.436, c2=-182.717 g=20.619\n",
            ">486, c1=-402.339, c2=-207.807 g=-10.022\n",
            ">487, c1=-411.354, c2=-229.390 g=6.450\n",
            ">488, c1=-405.086, c2=-199.050 g=1.783\n",
            ">489, c1=-396.687, c2=-141.763 g=-10.186\n",
            ">490, c1=-398.923, c2=-168.199 g=-9.670\n",
            ">491, c1=-394.961, c2=-195.552 g=9.527\n",
            ">492, c1=-417.998, c2=-218.987 g=33.393\n",
            ">493, c1=-412.987, c2=-223.077 g=10.347\n",
            ">494, c1=-394.427, c2=-117.997 g=-26.268\n",
            ">495, c1=-397.458, c2=-206.150 g=-0.013\n",
            ">496, c1=-396.879, c2=-182.884 g=8.606\n",
            ">497, c1=-417.793, c2=-229.832 g=15.764\n",
            ">498, c1=-423.371, c2=-193.119 g=19.970\n",
            ">499, c1=-412.912, c2=-194.364 g=8.918\n",
            ">500, c1=-410.368, c2=-213.516 g=33.944\n",
            ">501, c1=-413.902, c2=-241.604 g=35.566\n",
            ">502, c1=-422.760, c2=-263.895 g=19.785\n",
            ">503, c1=-410.515, c2=-113.383 g=-18.735\n",
            ">504, c1=-403.740, c2=-200.564 g=-9.453\n",
            ">505, c1=-418.210, c2=-171.279 g=-4.596\n",
            ">506, c1=-411.170, c2=-218.329 g=-4.600\n",
            ">507, c1=-422.795, c2=-189.972 g=-4.577\n",
            ">508, c1=-407.093, c2=-233.254 g=-11.547\n",
            ">509, c1=-429.968, c2=-185.794 g=-11.316\n",
            ">510, c1=-417.050, c2=-177.170 g=-16.046\n",
            ">511, c1=-405.378, c2=-115.342 g=-34.518\n",
            ">512, c1=-398.816, c2=-132.002 g=-34.740\n",
            ">513, c1=-411.112, c2=-185.195 g=-6.355\n",
            ">514, c1=-402.795, c2=-139.546 g=-36.570\n",
            ">515, c1=-406.265, c2=-196.522 g=1.222\n",
            ">516, c1=-398.787, c2=-130.667 g=-4.809\n",
            ">517, c1=-395.860, c2=-130.032 g=-67.936\n",
            ">518, c1=-416.951, c2=-194.552 g=-4.263\n",
            ">519, c1=-409.027, c2=-195.430 g=24.876\n",
            ">520, c1=-412.694, c2=-163.118 g=-0.982\n",
            ">521, c1=-421.921, c2=-216.933 g=25.223\n",
            ">522, c1=-416.970, c2=-222.787 g=23.386\n",
            ">523, c1=-423.267, c2=-216.695 g=20.753\n",
            ">524, c1=-426.523, c2=-231.605 g=29.411\n",
            ">525, c1=-420.096, c2=-245.007 g=19.717\n",
            ">526, c1=-444.101, c2=-200.922 g=16.034\n",
            ">527, c1=-427.696, c2=-270.892 g=49.841\n",
            ">528, c1=-443.730, c2=-234.733 g=3.187\n",
            ">529, c1=-455.347, c2=-180.982 g=-34.912\n",
            ">530, c1=-417.705, c2=-134.749 g=-57.848\n",
            ">531, c1=-423.026, c2=-114.535 g=-43.238\n",
            ">532, c1=-410.618, c2=-135.208 g=-26.166\n",
            ">533, c1=-400.154, c2=-132.343 g=6.138\n",
            ">534, c1=-395.718, c2=-116.861 g=-1.968\n",
            ">535, c1=-420.117, c2=-243.029 g=39.978\n",
            ">536, c1=-411.051, c2=-220.315 g=2.455\n",
            ">537, c1=-444.112, c2=-192.352 g=18.789\n",
            ">538, c1=-409.225, c2=-153.940 g=-20.521\n",
            ">539, c1=-434.214, c2=-245.998 g=12.565\n",
            ">540, c1=-442.617, c2=-192.762 g=-19.216\n",
            ">541, c1=-403.226, c2=-78.936 g=-76.388\n",
            ">542, c1=-393.347, c2=-129.994 g=-21.355\n",
            ">543, c1=-425.751, c2=-79.592 g=-44.859\n",
            ">544, c1=-397.972, c2=-110.096 g=-51.219\n",
            ">545, c1=-397.300, c2=-181.361 g=23.494\n",
            ">546, c1=-413.387, c2=-169.403 g=-13.775\n",
            ">547, c1=-421.061, c2=-206.892 g=-9.549\n",
            ">548, c1=-423.238, c2=-166.892 g=22.164\n",
            ">549, c1=-404.437, c2=-175.792 g=2.280\n",
            ">550, c1=-427.669, c2=-140.469 g=-5.585\n",
            ">551, c1=-418.496, c2=-164.321 g=-21.629\n",
            ">552, c1=-423.471, c2=-181.997 g=-3.807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0552.png and model_0552.h5\n",
            ">553, c1=-418.072, c2=-153.018 g=10.339\n",
            ">554, c1=-421.269, c2=-156.349 g=-2.575\n",
            ">555, c1=-389.126, c2=-128.729 g=-10.201\n",
            ">556, c1=-405.035, c2=-125.609 g=-43.394\n",
            ">557, c1=-399.391, c2=-75.228 g=-68.931\n",
            ">558, c1=-387.699, c2=-127.017 g=9.192\n",
            ">559, c1=-420.846, c2=-165.835 g=18.887\n",
            ">560, c1=-412.284, c2=-227.915 g=1.524\n",
            ">561, c1=-417.778, c2=-195.079 g=20.165\n",
            ">562, c1=-427.489, c2=-185.697 g=11.502\n",
            ">563, c1=-428.072, c2=-219.871 g=21.428\n",
            ">564, c1=-420.065, c2=-110.120 g=-66.489\n",
            ">565, c1=-387.476, c2=-125.230 g=13.357\n",
            ">566, c1=-424.710, c2=-133.408 g=-12.469\n",
            ">567, c1=-397.254, c2=-198.057 g=4.523\n",
            ">568, c1=-416.912, c2=-147.631 g=33.380\n",
            ">569, c1=-423.749, c2=-197.101 g=4.350\n",
            ">570, c1=-442.078, c2=-202.006 g=6.080\n",
            ">571, c1=-403.621, c2=-139.817 g=-16.409\n",
            ">572, c1=-402.691, c2=-38.909 g=-15.367\n",
            ">573, c1=-398.503, c2=-152.018 g=12.376\n",
            ">574, c1=-408.831, c2=-164.653 g=-13.420\n",
            ">575, c1=-420.760, c2=-160.688 g=-13.769\n",
            ">576, c1=-429.633, c2=-204.033 g=10.053\n",
            ">577, c1=-424.750, c2=-155.728 g=16.014\n",
            ">578, c1=-415.986, c2=-106.417 g=-68.057\n",
            ">579, c1=-417.091, c2=-107.203 g=-45.431\n",
            ">580, c1=-388.313, c2=-70.285 g=30.475\n",
            ">581, c1=-411.190, c2=-276.833 g=48.572\n",
            ">582, c1=-419.829, c2=-155.778 g=30.978\n",
            ">583, c1=-418.182, c2=-132.451 g=-28.047\n",
            ">584, c1=-420.812, c2=-157.216 g=-5.918\n",
            ">585, c1=-410.336, c2=-172.385 g=23.794\n",
            ">586, c1=-420.339, c2=-167.832 g=8.186\n",
            ">587, c1=-419.242, c2=-169.094 g=12.356\n",
            ">588, c1=-398.513, c2=-55.086 g=-42.890\n",
            ">589, c1=-427.588, c2=-167.537 g=-9.833\n",
            ">590, c1=-412.167, c2=-57.225 g=11.417\n",
            ">591, c1=-413.735, c2=-195.118 g=15.608\n",
            ">592, c1=-415.070, c2=-177.783 g=-4.103\n",
            ">593, c1=-422.761, c2=-139.252 g=-16.877\n",
            ">594, c1=-404.202, c2=-127.333 g=13.179\n",
            ">595, c1=-406.673, c2=-142.337 g=-4.853\n",
            ">596, c1=-397.231, c2=-150.201 g=3.694\n",
            ">597, c1=-425.897, c2=-67.352 g=-33.741\n",
            ">598, c1=-396.207, c2=-106.056 g=-99.169\n",
            ">599, c1=-376.877, c2=-7.617 g=-35.029\n",
            ">600, c1=-408.585, c2=-95.732 g=-69.601\n",
            ">601, c1=-386.588, c2=-80.709 g=-26.316\n",
            ">602, c1=-403.378, c2=-72.716 g=-48.130\n",
            ">603, c1=-402.819, c2=-168.739 g=18.323\n",
            ">604, c1=-413.583, c2=-109.813 g=27.890\n",
            ">605, c1=-422.177, c2=-236.331 g=27.847\n",
            ">606, c1=-402.487, c2=-137.085 g=-8.560\n",
            ">607, c1=-402.918, c2=-83.310 g=-10.643\n",
            ">608, c1=-382.471, c2=-58.922 g=18.792\n",
            ">609, c1=-411.276, c2=-141.583 g=0.811\n",
            ">610, c1=-392.442, c2=-81.546 g=-75.368\n",
            ">611, c1=-380.358, c2=-50.961 g=-24.772\n",
            ">612, c1=-386.707, c2=-93.739 g=-34.514\n",
            ">613, c1=-368.783, c2=40.727 g=-100.149\n",
            ">614, c1=-394.939, c2=-35.211 g=-25.423\n",
            ">615, c1=-369.153, c2=-112.478 g=7.426\n",
            ">616, c1=-412.464, c2=-56.934 g=-58.388\n",
            ">617, c1=-391.121, c2=-27.131 g=-124.588\n",
            ">618, c1=-344.394, c2=-32.253 g=-8.950\n",
            ">619, c1=-358.864, c2=-21.203 g=-33.630\n",
            ">620, c1=-353.673, c2=-17.342 g=-146.098\n",
            ">621, c1=-368.364, c2=-4.474 g=-34.276\n",
            ">622, c1=-366.236, c2=-55.350 g=-135.427\n",
            ">623, c1=-370.922, c2=-16.926 g=-20.636\n",
            ">624, c1=-373.307, c2=-122.129 g=-21.835\n",
            ">625, c1=-400.829, c2=-58.693 g=-2.856\n",
            ">626, c1=-406.145, c2=-52.765 g=-40.949\n",
            ">627, c1=-382.194, c2=-31.587 g=-69.180\n",
            ">628, c1=-375.232, c2=-36.007 g=-16.523\n",
            ">629, c1=-358.473, c2=-49.461 g=-48.930\n",
            ">630, c1=-353.627, c2=18.442 g=-0.725\n",
            ">631, c1=-346.161, c2=-81.224 g=-58.714\n",
            ">632, c1=-388.334, c2=-68.944 g=-44.793\n",
            ">633, c1=-349.879, c2=47.010 g=5.820\n",
            ">634, c1=-360.635, c2=-134.694 g=21.293\n",
            ">635, c1=-408.136, c2=-141.091 g=24.775\n",
            ">636, c1=-384.922, c2=-34.410 g=-77.528\n",
            ">637, c1=-393.018, c2=-36.693 g=-23.360\n",
            ">638, c1=-362.754, c2=29.732 g=-47.552\n",
            ">639, c1=-344.737, c2=-57.223 g=-6.025\n",
            ">640, c1=-355.648, c2=-28.502 g=45.249\n",
            ">641, c1=-380.210, c2=-120.580 g=-10.785\n",
            ">642, c1=-338.368, c2=-14.069 g=-26.703\n",
            ">643, c1=-378.882, c2=-103.709 g=-77.967\n",
            ">644, c1=-343.991, c2=28.204 g=6.363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0644.png and model_0644.h5\n",
            ">645, c1=-356.906, c2=-88.913 g=-21.992\n",
            ">646, c1=-377.834, c2=-74.812 g=-22.680\n",
            ">647, c1=-383.146, c2=6.250 g=-108.800\n",
            ">648, c1=-352.636, c2=-12.396 g=-71.680\n",
            ">649, c1=-361.726, c2=16.989 g=-38.388\n",
            ">650, c1=-371.746, c2=-80.637 g=-101.052\n",
            ">651, c1=-359.131, c2=36.293 g=12.876\n",
            ">652, c1=-329.245, c2=-72.358 g=-34.213\n",
            ">653, c1=-361.316, c2=-106.630 g=-22.532\n",
            ">654, c1=-374.440, c2=49.236 g=-17.363\n",
            ">655, c1=-340.438, c2=1.534 g=-112.326\n",
            ">656, c1=-342.657, c2=53.540 g=-1.137\n",
            ">657, c1=-351.941, c2=-44.506 g=-140.806\n",
            ">658, c1=-341.255, c2=52.701 g=-55.832\n",
            ">659, c1=-334.839, c2=133.856 g=-101.331\n",
            ">660, c1=-358.057, c2=37.784 g=-0.810\n",
            ">661, c1=-350.603, c2=-102.872 g=77.359\n",
            ">662, c1=-350.072, c2=-97.016 g=-7.239\n",
            ">663, c1=-354.335, c2=-21.762 g=-3.538\n",
            ">664, c1=-355.210, c2=-49.645 g=-77.252\n",
            ">665, c1=-358.460, c2=71.141 g=-17.147\n",
            ">666, c1=-361.461, c2=-5.072 g=-64.909\n",
            ">667, c1=-315.677, c2=82.640 g=-131.541\n",
            ">668, c1=-303.414, c2=92.317 g=-4.614\n",
            ">669, c1=-356.689, c2=32.844 g=-82.471\n",
            ">670, c1=-323.680, c2=38.210 g=-64.731\n",
            ">671, c1=-334.865, c2=36.570 g=-30.254\n",
            ">672, c1=-359.424, c2=28.991 g=-58.350\n",
            ">673, c1=-299.352, c2=85.676 g=-11.791\n",
            ">674, c1=-320.815, c2=-2.671 g=-105.152\n",
            ">675, c1=-320.755, c2=96.232 g=-182.173\n",
            ">676, c1=-285.206, c2=201.396 g=-87.403\n",
            ">677, c1=-324.783, c2=41.807 g=-71.363\n",
            ">678, c1=-301.962, c2=61.356 g=-8.909\n",
            ">679, c1=-313.207, c2=5.178 g=-122.362\n",
            ">680, c1=-328.495, c2=104.248 g=-42.420\n",
            ">681, c1=-301.575, c2=72.219 g=-86.642\n",
            ">682, c1=-281.740, c2=120.729 g=-24.589\n",
            ">683, c1=-330.631, c2=-36.083 g=-59.822\n",
            ">684, c1=-348.508, c2=48.210 g=-20.148\n",
            ">685, c1=-294.684, c2=19.643 g=-23.639\n",
            ">686, c1=-289.066, c2=63.001 g=-104.518\n",
            ">687, c1=-301.123, c2=152.963 g=27.367\n",
            ">688, c1=-307.534, c2=34.370 g=-77.544\n",
            ">689, c1=-301.137, c2=46.779 g=-85.757\n",
            ">690, c1=-289.700, c2=183.206 g=-157.057\n",
            ">691, c1=-311.855, c2=145.631 g=-125.137\n",
            ">692, c1=-331.748, c2=174.918 g=-34.048\n",
            ">693, c1=-326.010, c2=63.927 g=-65.567\n",
            ">694, c1=-279.873, c2=107.377 g=-149.020\n",
            ">695, c1=-296.729, c2=191.807 g=-100.025\n",
            ">696, c1=-338.157, c2=115.072 g=-46.338\n",
            ">697, c1=-291.273, c2=86.949 g=-184.055\n",
            ">698, c1=-283.047, c2=137.530 g=-128.317\n",
            ">699, c1=-273.377, c2=195.934 g=-75.344\n",
            ">700, c1=-324.304, c2=36.110 g=-51.380\n",
            ">701, c1=-312.943, c2=98.200 g=-50.768\n",
            ">702, c1=-261.811, c2=96.886 g=-57.060\n",
            ">703, c1=-259.470, c2=100.477 g=-83.253\n",
            ">704, c1=-287.321, c2=155.568 g=-135.079\n",
            ">705, c1=-272.160, c2=212.401 g=-52.614\n",
            ">706, c1=-323.105, c2=102.688 g=-126.192\n",
            ">707, c1=-256.240, c2=182.072 g=-53.025\n",
            ">708, c1=-279.353, c2=162.269 g=-24.505\n",
            ">709, c1=-278.727, c2=113.825 g=-142.751\n",
            ">710, c1=-296.999, c2=162.432 g=-149.437\n",
            ">711, c1=-250.070, c2=243.250 g=-185.268\n",
            ">712, c1=-310.458, c2=223.100 g=-223.535\n",
            ">713, c1=-298.247, c2=216.745 g=-107.976\n",
            ">714, c1=-304.071, c2=195.324 g=-284.588\n",
            ">715, c1=-279.548, c2=283.692 g=-166.717\n",
            ">716, c1=-333.247, c2=237.741 g=-271.740\n",
            ">717, c1=-320.084, c2=310.333 g=-181.913\n",
            ">718, c1=-316.929, c2=232.783 g=-95.648\n",
            ">719, c1=-315.927, c2=221.409 g=-168.685\n",
            ">720, c1=-299.671, c2=209.635 g=-130.361\n",
            ">721, c1=-307.222, c2=221.662 g=-184.747\n",
            ">722, c1=-308.074, c2=259.633 g=-62.481\n",
            ">723, c1=-265.639, c2=208.196 g=-158.102\n",
            ">724, c1=-285.040, c2=221.794 g=-126.501\n",
            ">725, c1=-319.950, c2=184.871 g=-43.172\n",
            ">726, c1=-291.028, c2=184.214 g=-185.640\n",
            ">727, c1=-259.403, c2=212.577 g=-90.125\n",
            ">728, c1=-274.505, c2=231.276 g=-134.085\n",
            ">729, c1=-267.013, c2=217.861 g=-94.558\n",
            ">730, c1=-262.702, c2=203.352 g=-196.669\n",
            ">731, c1=-295.698, c2=276.426 g=-273.433\n",
            ">732, c1=-357.264, c2=301.880 g=-212.141\n",
            ">733, c1=-321.190, c2=278.082 g=-141.218\n",
            ">734, c1=-286.522, c2=244.179 g=-240.423\n",
            ">735, c1=-289.759, c2=271.506 g=-112.325\n",
            ">736, c1=-275.599, c2=202.156 g=-220.014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0736.png and model_0736.h5\n",
            ">737, c1=-305.901, c2=289.953 g=-176.242\n",
            ">738, c1=-346.745, c2=274.555 g=-321.983\n",
            ">739, c1=-289.082, c2=342.693 g=-178.401\n",
            ">740, c1=-342.684, c2=281.265 g=-294.430\n",
            ">741, c1=-330.916, c2=292.022 g=-167.712\n",
            ">742, c1=-316.240, c2=255.156 g=-282.498\n",
            ">743, c1=-332.882, c2=330.190 g=-152.254\n",
            ">744, c1=-325.562, c2=231.534 g=-168.764\n",
            ">745, c1=-317.757, c2=278.700 g=-245.234\n",
            ">746, c1=-304.083, c2=285.727 g=-167.357\n",
            ">747, c1=-350.328, c2=269.665 g=-188.370\n",
            ">748, c1=-292.522, c2=266.441 g=-291.093\n",
            ">749, c1=-278.651, c2=366.237 g=-204.483\n",
            ">750, c1=-325.847, c2=345.052 g=-253.928\n",
            ">751, c1=-351.733, c2=308.796 g=-302.352\n",
            ">752, c1=-324.228, c2=359.751 g=-233.147\n",
            ">753, c1=-345.546, c2=321.809 g=-259.350\n",
            ">754, c1=-334.633, c2=320.471 g=-326.032\n",
            ">755, c1=-373.931, c2=318.432 g=-232.026\n",
            ">756, c1=-344.643, c2=323.773 g=-359.263\n",
            ">757, c1=-356.756, c2=370.539 g=-314.236\n",
            ">758, c1=-366.193, c2=365.324 g=-375.552\n",
            ">759, c1=-400.898, c2=360.260 g=-226.933\n",
            ">760, c1=-357.860, c2=342.959 g=-255.216\n",
            ">761, c1=-381.935, c2=316.199 g=-183.493\n",
            ">762, c1=-354.152, c2=266.603 g=-237.952\n",
            ">763, c1=-364.974, c2=321.749 g=-293.692\n",
            ">764, c1=-378.874, c2=321.841 g=-182.669\n",
            ">765, c1=-368.332, c2=302.732 g=-281.791\n",
            ">766, c1=-335.830, c2=356.537 g=-286.080\n",
            ">767, c1=-374.993, c2=342.816 g=-188.134\n",
            ">768, c1=-366.219, c2=304.155 g=-330.472\n",
            ">769, c1=-374.623, c2=351.339 g=-257.842\n",
            ">770, c1=-368.056, c2=341.483 g=-407.233\n",
            ">771, c1=-399.879, c2=396.792 g=-283.114\n",
            ">772, c1=-360.454, c2=359.552 g=-363.061\n",
            ">773, c1=-391.696, c2=374.382 g=-274.382\n",
            ">774, c1=-384.613, c2=341.536 g=-369.723\n",
            ">775, c1=-408.769, c2=384.306 g=-331.756\n",
            ">776, c1=-390.722, c2=369.409 g=-380.463\n",
            ">777, c1=-382.134, c2=416.014 g=-373.049\n",
            ">778, c1=-410.278, c2=401.316 g=-283.075\n",
            ">779, c1=-420.517, c2=373.622 g=-358.310\n",
            ">780, c1=-381.406, c2=372.040 g=-223.769\n",
            ">781, c1=-395.468, c2=314.100 g=-248.339\n",
            ">782, c1=-393.213, c2=327.499 g=-195.588\n",
            ">783, c1=-382.662, c2=290.828 g=-306.436\n",
            ">784, c1=-399.405, c2=340.702 g=-224.952\n",
            ">785, c1=-381.220, c2=332.615 g=-330.673\n",
            ">786, c1=-365.409, c2=382.586 g=-347.726\n",
            ">787, c1=-370.974, c2=397.465 g=-259.286\n",
            ">788, c1=-419.290, c2=349.445 g=-350.347\n",
            ">789, c1=-393.178, c2=377.883 g=-319.232\n",
            ">790, c1=-404.280, c2=401.315 g=-319.554\n",
            ">791, c1=-413.016, c2=373.109 g=-373.033\n",
            ">792, c1=-405.078, c2=415.821 g=-341.468\n",
            ">793, c1=-410.297, c2=420.176 g=-380.854\n",
            ">794, c1=-426.407, c2=418.097 g=-430.885\n",
            ">795, c1=-428.912, c2=448.997 g=-371.529\n",
            ">796, c1=-426.094, c2=417.627 g=-419.660\n",
            ">797, c1=-439.174, c2=409.692 g=-279.006\n",
            ">798, c1=-429.293, c2=375.440 g=-408.040\n",
            ">799, c1=-419.225, c2=414.039 g=-353.034\n",
            ">800, c1=-442.413, c2=393.259 g=-438.450\n",
            ">801, c1=-420.886, c2=399.781 g=-299.440\n",
            ">802, c1=-437.722, c2=409.582 g=-438.534\n",
            ">803, c1=-427.815, c2=451.261 g=-445.061\n",
            ">804, c1=-449.421, c2=451.096 g=-420.172\n",
            ">805, c1=-421.257, c2=445.571 g=-376.501\n",
            ">806, c1=-449.898, c2=426.984 g=-448.462\n",
            ">807, c1=-443.815, c2=444.495 g=-390.838\n",
            ">808, c1=-449.798, c2=428.779 g=-447.293\n",
            ">809, c1=-443.137, c2=451.623 g=-411.372\n",
            ">810, c1=-460.349, c2=431.935 g=-366.730\n",
            ">811, c1=-457.255, c2=406.341 g=-441.684\n",
            ">812, c1=-454.861, c2=432.899 g=-383.311\n",
            ">813, c1=-465.981, c2=424.102 g=-423.579\n",
            ">814, c1=-446.834, c2=440.518 g=-383.947\n",
            ">815, c1=-460.497, c2=410.218 g=-373.743\n",
            ">816, c1=-467.698, c2=417.507 g=-272.627\n",
            ">817, c1=-449.901, c2=385.219 g=-381.008\n",
            ">818, c1=-445.959, c2=405.728 g=-315.160\n",
            ">819, c1=-428.562, c2=408.227 g=-411.903\n",
            ">820, c1=-446.918, c2=426.505 g=-327.289\n",
            ">821, c1=-457.143, c2=428.583 g=-364.886\n",
            ">822, c1=-458.352, c2=404.232 g=-408.161\n",
            ">823, c1=-451.030, c2=419.135 g=-452.929\n",
            ">824, c1=-456.577, c2=464.861 g=-389.286\n",
            ">825, c1=-471.829, c2=456.684 g=-476.302\n",
            ">826, c1=-458.140, c2=472.603 g=-421.382\n",
            ">827, c1=-463.508, c2=456.823 g=-415.484\n",
            ">828, c1=-482.297, c2=449.288 g=-478.768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0828.png and model_0828.h5\n",
            ">829, c1=-471.881, c2=454.724 g=-410.394\n",
            ">830, c1=-472.067, c2=438.215 g=-416.050\n",
            ">831, c1=-483.945, c2=445.060 g=-445.818\n",
            ">832, c1=-488.523, c2=442.665 g=-378.987\n",
            ">833, c1=-480.404, c2=434.870 g=-444.294\n",
            ">834, c1=-495.293, c2=446.336 g=-374.019\n",
            ">835, c1=-458.407, c2=444.714 g=-459.640\n",
            ">836, c1=-476.188, c2=457.973 g=-416.085\n",
            ">837, c1=-466.221, c2=439.629 g=-471.138\n",
            ">838, c1=-478.125, c2=460.386 g=-451.941\n",
            ">839, c1=-488.092, c2=464.227 g=-394.487\n",
            ">840, c1=-473.001, c2=437.006 g=-437.973\n",
            ">841, c1=-489.050, c2=434.606 g=-383.595\n",
            ">842, c1=-475.372, c2=410.020 g=-454.382\n",
            ">843, c1=-489.529, c2=454.138 g=-433.386\n",
            ">844, c1=-474.428, c2=456.164 g=-412.155\n",
            ">845, c1=-477.807, c2=444.807 g=-392.785\n",
            ">846, c1=-482.332, c2=424.881 g=-367.088\n",
            ">847, c1=-478.666, c2=404.118 g=-411.965\n",
            ">848, c1=-472.878, c2=429.891 g=-472.956\n",
            ">849, c1=-482.336, c2=450.620 g=-411.889\n",
            ">850, c1=-484.691, c2=453.188 g=-466.652\n",
            ">851, c1=-483.528, c2=448.876 g=-370.185\n",
            ">852, c1=-487.455, c2=427.937 g=-433.044\n",
            ">853, c1=-463.266, c2=437.102 g=-383.176\n",
            ">854, c1=-476.296, c2=413.696 g=-412.811\n",
            ">855, c1=-484.780, c2=425.488 g=-358.167\n",
            ">856, c1=-464.244, c2=397.040 g=-413.673\n",
            ">857, c1=-490.193, c2=400.675 g=-431.677\n",
            ">858, c1=-479.224, c2=446.617 g=-440.317\n",
            ">859, c1=-470.975, c2=461.246 g=-477.999\n",
            ">860, c1=-459.361, c2=461.647 g=-448.272\n",
            ">861, c1=-493.550, c2=452.429 g=-448.937\n",
            ">862, c1=-504.232, c2=462.859 g=-425.471\n",
            ">863, c1=-495.675, c2=442.310 g=-446.591\n",
            ">864, c1=-481.831, c2=451.578 g=-439.001\n",
            ">865, c1=-485.564, c2=452.643 g=-439.685\n",
            ">866, c1=-496.532, c2=445.444 g=-476.875\n",
            ">867, c1=-499.657, c2=450.264 g=-367.890\n",
            ">868, c1=-493.078, c2=437.089 g=-360.654\n",
            ">869, c1=-485.459, c2=418.376 g=-431.566\n",
            ">870, c1=-493.842, c2=437.892 g=-445.730\n",
            ">871, c1=-485.889, c2=448.285 g=-392.833\n",
            ">872, c1=-489.715, c2=421.159 g=-445.356\n",
            ">873, c1=-500.247, c2=438.654 g=-465.797\n",
            ">874, c1=-490.592, c2=459.330 g=-396.016\n",
            ">875, c1=-485.034, c2=444.606 g=-463.580\n",
            ">876, c1=-508.404, c2=458.210 g=-395.910\n",
            ">877, c1=-485.517, c2=426.102 g=-421.296\n",
            ">878, c1=-490.704, c2=436.586 g=-370.564\n",
            ">879, c1=-495.445, c2=413.396 g=-482.125\n",
            ">880, c1=-490.716, c2=445.917 g=-435.042\n",
            ">881, c1=-493.136, c2=437.368 g=-438.150\n",
            ">882, c1=-482.956, c2=444.595 g=-453.778\n",
            ">883, c1=-506.660, c2=457.677 g=-479.754\n",
            ">884, c1=-498.844, c2=453.841 g=-402.137\n",
            ">885, c1=-492.239, c2=426.864 g=-477.809\n",
            ">886, c1=-500.745, c2=440.136 g=-438.953\n",
            ">887, c1=-496.760, c2=431.653 g=-382.102\n",
            ">888, c1=-485.506, c2=419.206 g=-423.761\n",
            ">889, c1=-504.891, c2=429.769 g=-373.369\n",
            ">890, c1=-497.613, c2=405.769 g=-364.117\n",
            ">891, c1=-485.926, c2=409.623 g=-329.323\n",
            ">892, c1=-485.065, c2=395.894 g=-426.452\n",
            ">893, c1=-487.488, c2=437.761 g=-437.183\n",
            ">894, c1=-485.052, c2=450.141 g=-384.403\n",
            ">895, c1=-496.852, c2=425.684 g=-451.076\n",
            ">896, c1=-488.479, c2=415.245 g=-429.854\n",
            ">897, c1=-481.635, c2=445.133 g=-415.422\n",
            ">898, c1=-492.203, c2=414.536 g=-468.591\n",
            ">899, c1=-498.996, c2=416.601 g=-403.526\n",
            ">900, c1=-497.996, c2=418.544 g=-406.791\n",
            ">901, c1=-499.152, c2=411.806 g=-451.964\n",
            ">902, c1=-504.092, c2=392.008 g=-416.124\n",
            ">903, c1=-493.179, c2=403.784 g=-355.040\n",
            ">904, c1=-519.042, c2=371.856 g=-379.329\n",
            ">905, c1=-489.487, c2=380.197 g=-367.006\n",
            ">906, c1=-498.507, c2=388.397 g=-417.085\n",
            ">907, c1=-489.381, c2=393.178 g=-340.460\n",
            ">908, c1=-493.849, c2=377.211 g=-387.438\n",
            ">909, c1=-503.184, c2=398.233 g=-426.827\n",
            ">910, c1=-485.243, c2=410.816 g=-339.279\n",
            ">911, c1=-502.754, c2=383.732 g=-342.975\n",
            ">912, c1=-495.004, c2=376.356 g=-423.842\n",
            ">913, c1=-501.483, c2=392.282 g=-369.346\n",
            ">914, c1=-498.598, c2=400.604 g=-437.530\n",
            ">915, c1=-500.181, c2=413.844 g=-374.401\n",
            ">916, c1=-479.435, c2=403.442 g=-464.511\n",
            ">917, c1=-494.833, c2=415.990 g=-437.339\n",
            ">918, c1=-506.946, c2=411.112 g=-397.790\n",
            ">919, c1=-509.343, c2=398.786 g=-459.541\n",
            ">920, c1=-499.479, c2=418.610 g=-365.603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0920.png and model_0920.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "durWmwCGWf5t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}